{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA\n",
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2022-12-25 13:32:45 - get_logger - Writing log to logs/graphnet_20221225-133245.log\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:graphnet:Writing log to logs/graphnet_20221225-133245.log\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../olympus')\n",
    "sys.path.insert(0, '../graphnet/src')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "#from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import torch\n",
    "import torch_cluster\n",
    "import torch_geometric\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from nemesis.event_generation.detector import make_line, generate_noise, Detector, make_triang\n",
    "from nemesis.plotting import plot_event, plot_events, plot_confusion\n",
    "from nemesis.data_handling.utils import event_labelling\n",
    "from nemesis.node_features.feature_generation import generate_features\n",
    "from nemesis.evaluation.evaluation import energy_gap_test, model_evaluation\n",
    "from nemesis.evaluation.utils import count_parameters\n",
    "from nemesis.models.train import train_model\n",
    "from nemesis.models.gnns import Dynamic_class\n",
    "\n",
    "from torch.nn import Linear, Identity, ReLU, Softmax, Dropout, LeakyReLU\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import knn_graph, TAGConv, global_mean_pool, global_max_pool, BatchNorm,  global_add_pool, EdgeConv, DynamicEdgeConv\n",
    "\n",
    "from graphnet.models.gnn.dynedge import DynEdge\n",
    "from graphnet.components.layers import DynEdgeConv\n",
    "from graphnet.models.gnn.gnn import GNN\n",
    "from graphnet.models.utils import calculate_xyzt_homophily, calculate_xyz_homophily_POne\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import evaluation modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA\n"
     ]
    }
   ],
   "source": [
    "outpath = \".\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA')\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('CPU')\n",
    "    \n",
    "rng = np.random.RandomState(31338)\n",
    "oms_per_line = 20\n",
    "dist_z = 50 # m\n",
    "dark_noise_rate = 16 * 1e-5  # 1/ns\n",
    "side_len = 100 # m\n",
    "pmts_per_module = 16\n",
    "pmt_cath_area_r = 75E-3 / 2 # m\n",
    "module_radius = 0.21 # m\n",
    "\n",
    "efficiency = pmts_per_module * (pmt_cath_area_r)**2 * np.pi / (4*np.pi*module_radius**2)\n",
    "det = make_triang(side_len, oms_per_line, dist_z, dark_noise_rate, rng, efficiency=efficiency)\n",
    "module_positions = jnp.asarray(det.module_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascades, cascade_records = pickle.load(open(os.path.join(outpath, f\"events/cascades.pickle\"), \"rb\"))\n",
    "tracks, track_records = pickle.load(open(os.path.join(outpath, f\"events/tracks.pickle\"), \"rb\"))\n",
    "stracks, strack_records = pickle.load(open(os.path.join(outpath, f\"events/stracks.pickle\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascades1, cascade_records1 = pickle.load(open(f\"/dss/pone/pone_events/cascades_15000ev_3.5-6.5.pickle\", \"rb\"))\n",
    "print('cascades DONE!')\n",
    "tracks1, track_records1 = pickle.load(open(f\"/dss/pone/pone_events/tracks_15000ev_3.5-6.5.pickle\", \"rb\"))\n",
    "print('tracks DONE!')\n",
    "stracks1, strack_records1 = pickle.load(open(f\"/dss/pone/pone_events/stracks_15000ev_3.5-6.5.pickle\", \"rb\"))\n",
    "print('starting tracks DONE!')\n",
    "cascades2, cascade_records2 = pickle.load(open(f\"/dss/pone/pone_events/cascades_15000ev_3.5-6.5_2.pickle\", \"rb\"))\n",
    "print('cascades DONE!')\n",
    "tracks2, track_records2 = pickle.load(open(f\"/dss/pone/pone_events/tracks_15000ev_3.5-6.5_2.pickle\", \"rb\"))\n",
    "print('tracks DONE!')\n",
    "stracks2, strack_records2 = pickle.load(open(f\"/dss/pone/pone_events/stracks_15000ev_3.5-6.5_2.pickle\", \"rb\"))\n",
    "print('starting tracks DONE!')\n",
    "\n",
    "cascades = cascades1 + cascades2\n",
    "cascade_records = cascade_records1 + cascade_records2\n",
    "tracks = tracks1 + tracks2\n",
    "track_records = track_records1 + track_records2\n",
    "stracks = stracks1 + stracks2\n",
    "strack_records = strack_records1 + strack_records2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 1500 1500\n"
     ]
    }
   ],
   "source": [
    "cascade_labels, track_labels, strack_labels = event_labelling(track_records, strack_records, cascade_records, det_hull=(75.0, 1000.0))\n",
    "\n",
    "all_events = cascades + tracks + stracks\n",
    "all_records = cascade_records + track_records + strack_records\n",
    "all_labels = cascade_labels + track_labels + strack_labels\n",
    "print(len(all_events), len(all_records), len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be235c34b58647f39dea4b99937da07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_array = generate_features(det, all_events, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(data_array, open(\"/dss/pone/pone_events/features_arrays/data_array_90k_k8_R75.pickle\", \"wb\"))\n",
    "#data_array = pickle.load(open(\"/dss/pone/pone_events/features_arrays/data_array_90k_k8_R75.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(234567)\n",
    "\n",
    "indices = np.arange(len(data_array))\n",
    "random.shuffle(indices)\n",
    "\n",
    "\n",
    "shuffled_data = [data_array[i] for i in indices]\n",
    "split_test = int(len(shuffled_data)*0.9)\n",
    "training_data = shuffled_data[:split_test]\n",
    "split_val = int(len(training_data)*0.9)\n",
    "train_dataset = training_data[:split_val]\n",
    "val_dataset = training_data[split_val:]\n",
    "\n",
    "test_dataset = shuffled_data[split_test:]\n",
    "test_indices = indices[split_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/app/nemesis/DynamicEdge_GraphNet.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f617765736f6d655f6d6573746f7266227d/app/nemesis/DynamicEdge_GraphNet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m num_node_features\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f617765736f6d655f6d6573746f7266227d/app/nemesis/DynamicEdge_GraphNet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m model \u001b[39m=\u001b[39m Dynamic_class(out_channels\u001b[39m=\u001b[39mnum_classes, k\u001b[39m=\u001b[39mk)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f617765736f6d655f6d6573746f7266227d/app/nemesis/DynamicEdge_GraphNet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m model\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    580\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    580\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    580\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "num_classes=4\n",
    "patience = 200\n",
    "batch_size = 200\n",
    "learning_rates = [0.001]\n",
    "use_writer = False\n",
    "print_step = 1\n",
    "k = 8\n",
    "schedulers = ['ReduceLROnPlateau']#, 'CosineAnnealingLR', 'OneCycleLR', 'MultiStepLR']\n",
    "label_map = {0:\"Contained cascade\", 1:'Throughgoing Track', 2:\"Starts in detector\", 3:\"Rest of events\"}\n",
    "best_acc, patience_count = 0, 0\n",
    "all_trains_acc, all_vals_acc, all_trains_loss, all_vals_loss = [], [], [], []\n",
    "num_node_features=15\n",
    "\n",
    "model = Dynamic_class(out_channels=num_classes, k=k)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+------------+\n",
      "|         Modules          | Parameters |\n",
      "+--------------------------+------------+\n",
      "|   conv11.lins.0.weight   |    960     |\n",
      "|    conv11.lins.0.bias    |     64     |\n",
      "|   conv11.lins.1.weight   |    960     |\n",
      "|    conv11.lins.1.bias    |     64     |\n",
      "|   conv11.lins.2.weight   |    960     |\n",
      "|    conv11.lins.2.bias    |     64     |\n",
      "|   conv11.lins.3.weight   |    960     |\n",
      "|    conv11.lins.3.bias    |     64     |\n",
      "|   conv11.lins.4.weight   |    960     |\n",
      "|    conv11.lins.4.bias    |     64     |\n",
      "|   conv12.lins.0.weight   |    4096    |\n",
      "|    conv12.lins.0.bias    |     64     |\n",
      "|   conv12.lins.1.weight   |    4096    |\n",
      "|    conv12.lins.1.bias    |     64     |\n",
      "|   conv12.lins.2.weight   |    4096    |\n",
      "|    conv12.lins.2.bias    |     64     |\n",
      "|   conv12.lins.3.weight   |    4096    |\n",
      "|    conv12.lins.3.bias    |     64     |\n",
      "|   conv12.lins.4.weight   |    4096    |\n",
      "|    conv12.lins.4.bias    |     64     |\n",
      "| BatchNorm1.module.weight |     64     |\n",
      "|  BatchNorm1.module.bias  |     64     |\n",
      "|   conv21.lins.0.weight   |    4096    |\n",
      "|    conv21.lins.0.bias    |     64     |\n",
      "|   conv21.lins.1.weight   |    4096    |\n",
      "|    conv21.lins.1.bias    |     64     |\n",
      "|   conv21.lins.2.weight   |    4096    |\n",
      "|    conv21.lins.2.bias    |     64     |\n",
      "|   conv21.lins.3.weight   |    4096    |\n",
      "|    conv21.lins.3.bias    |     64     |\n",
      "|   conv22.lins.0.weight   |    2048    |\n",
      "|    conv22.lins.0.bias    |     32     |\n",
      "|   conv22.lins.1.weight   |    2048    |\n",
      "|    conv22.lins.1.bias    |     32     |\n",
      "|   conv22.lins.2.weight   |    2048    |\n",
      "|    conv22.lins.2.bias    |     32     |\n",
      "|   conv22.lins.3.weight   |    2048    |\n",
      "|    conv22.lins.3.bias    |     32     |\n",
      "| BatchNorm2.module.weight |     32     |\n",
      "|  BatchNorm2.module.bias  |     32     |\n",
      "|     conv31.nn.weight     |    4096    |\n",
      "|      conv31.nn.bias      |     64     |\n",
      "|     conv32.nn.weight     |    8192    |\n",
      "|      conv32.nn.bias      |     64     |\n",
      "| BatchNorm3.module.weight |     64     |\n",
      "|  BatchNorm3.module.bias  |     64     |\n",
      "|     conv41.nn.weight     |    4096    |\n",
      "|      conv41.nn.bias      |     32     |\n",
      "|     conv42.nn.weight     |    2048    |\n",
      "|      conv42.nn.bias      |     32     |\n",
      "| BatchNorm4.module.weight |     32     |\n",
      "|  BatchNorm4.module.bias  |     32     |\n",
      "|       lin1.weight        |   24576    |\n",
      "|        lin1.bias         |    128     |\n",
      "|    mlp.lins.0.weight     |    4096    |\n",
      "|     mlp.lins.0.bias      |     32     |\n",
      "|    mlp.lins.1.weight     |    128     |\n",
      "|     mlp.lins.1.bias      |     4      |\n",
      "|    mlp.norms.0.weight    |     32     |\n",
      "|     mlp.norms.0.bias     |     32     |\n",
      "+--------------------------+------------+\n",
      "Total Trainable Params: 98916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98916"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffda6cf6b6c4e0fad0e77581caf4548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/app/nemesis/DynamicEdge_GraphNet.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f617765736f6d655f6d6573746f7266227d/app/nemesis/DynamicEdge_GraphNet.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model, all_trains_acc, all_vals_acc \u001b[39m=\u001b[39m train_model(model, train_dataset, val_dataset, label_map, k\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, print_step\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f617765736f6d655f6d6573746f7266227d/app/nemesis/DynamicEdge_GraphNet.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(all_trains_acc), \u001b[39mlen\u001b[39m(all_trains_acc)), all_trains_acc, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Accuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f617765736f6d655f6d6573746f7266227d/app/nemesis/DynamicEdge_GraphNet.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(all_vals_acc), \u001b[39mlen\u001b[39m(all_vals_acc)), all_vals_acc, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValidation Accuracy\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/app/nemesis/nemesis/models/train.py:81\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, label_map, k, lr, batch_size, epochs, patience, print_step, use_writer)\u001b[0m\n\u001b[1;32m     77\u001b[0m all_trains_acc, all_vals_acc, all_trains_loss, all_vals_loss \u001b[39m=\u001b[39m [], [], [], []\n\u001b[1;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> 81\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m model_train\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     82\u001b[0m     val_loss, val_acc \u001b[39m=\u001b[39m model_train\u001b[39m.\u001b[39mvalidation()\n\u001b[1;32m     84\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m print_step \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/app/nemesis/nemesis/models/train.py:38\u001b[0m, in \u001b[0;36mmodel_training.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m data\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m loss, pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_loss(data)\n\u001b[0;32m---> 38\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem() \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(torch\u001b[39m.\u001b[39munique(data\u001b[39m.\u001b[39mbatch))\n\u001b[1;32m     39\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((pred \u001b[39m==\u001b[39m (data\u001b[39m.\u001b[39my))\u001b[39m.\u001b[39msum())\n\u001b[1;32m     40\u001b[0m loss\u001b[39m.\u001b[39mbackward()  \u001b[39m# Derive gradients.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model, all_trains_acc, all_vals_acc = train_model(model, train_dataset, val_dataset, label_map, k=8, epochs=200, patience=200, print_step=1)\n",
    "plt.plot(np.linspace(0, len(all_trains_acc), len(all_trains_acc)), all_trains_acc, label=\"Training Accuracy\")\n",
    "plt.plot(np.linspace(0, len(all_vals_acc), len(all_vals_acc)), all_vals_acc, label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "fig1, miss_idx1, test_acc=model_evaluation(model, test_loader, all_events, all_records, all_labels, label_map, test_indices)\n",
    "print('The test accuracy achieved is: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(outpath, \"saved_models/model.pt\"))\n",
    "#torch.save(model, os.path.join(outpath, \"./Own_model_R_75_k8.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascades_test, cascade_records_test = pickle.load(open(os.path.join(outpath, \"event_join/test_loaders/250test_cascades_all_mc.pickle\"), \"rb\"))\n",
    "tracks_test,   track_records_test   = pickle.load(open(os.path.join(outpath, \"event_join/test_loaders/250test_tracks_all_mc.pickle\"), \"rb\"))\n",
    "stracks_test, strack_records_test   = pickle.load(open(os.path.join(outpath, \"event_join/test_loaders/250test_stracks_all_mc.pickle\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'event_labelling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/arturopp/repos/nemesis/DynamicEdge_GraphNet.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arturopp/repos/nemesis/DynamicEdge_GraphNet.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cascade_labels_test, track_labels_test, strack_labels_test \u001b[39m=\u001b[39m event_labelling(track_records_test, strack_records_test, cascade_records_test, det_hull\u001b[39m=\u001b[39m[\u001b[39m75\u001b[39m, \u001b[39m1100\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arturopp/repos/nemesis/DynamicEdge_GraphNet.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m all_events_test \u001b[39m=\u001b[39m cascades_test \u001b[39m+\u001b[39m tracks_test \u001b[39m+\u001b[39m stracks_test\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arturopp/repos/nemesis/DynamicEdge_GraphNet.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m all_records_test \u001b[39m=\u001b[39m cascade_records_test \u001b[39m+\u001b[39m track_records_test \u001b[39m+\u001b[39m strack_records_test\n",
      "\u001b[0;31mNameError\u001b[0m: name 'event_labelling' is not defined"
     ]
    }
   ],
   "source": [
    "cascade_labels_test, track_labels_test, strack_labels_test = event_labelling(track_records_test, strack_records_test, cascade_records_test, det_hull=[75, 1100])\n",
    "all_events_test = cascades_test + tracks_test + stracks_test\n",
    "all_records_test = cascade_records_test + track_records_test + strack_records_test\n",
    "all_labels_test = cascade_labels_test + track_labels_test + strack_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_to_evaluate = energy_gap_test(det, model, all_events_test, all_records_test, all_labels_test, num_divisions=10, k=8)\n",
    "energy_divisions = gaps_to_evaluate.energy_division_loaders()\n",
    "fig, test_accuracies, misscls_idx = gaps_to_evaluate.energy_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
