{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../olympus')\n",
    "sys.path.insert(0, '../graphnet/src')\n",
    "sys.path.insert(0, '../gnn_testbed')\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"0.1\"\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "#from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import torch\n",
    "import torch_cluster\n",
    "import torch_geometric\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from nemesis.event_generation.detector import make_line, generate_noise, Detector, make_triang\n",
    "from nemesis.plotting import plot_event, plot_events, plot_confusion\n",
    "from nemesis.data_handling.utils import event_labelling\n",
    "from nemesis.node_features.feature_generation import generate_features\n",
    "from nemesis.evaluation.evaluation import model_evaluation, energy_division_loaders, energy_evaluation\n",
    "from nemesis.evaluation.utils import count_parameters\n",
    "from nemesis.models.train import train_model\n",
    "from nemesis.models.gnns import Dynamic_class, DynEdge_modified, Dyn_own\n",
    "\n",
    "from torch.nn import Linear, Identity, ReLU, Softmax, Dropout, LeakyReLU\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import knn_graph, TAGConv, global_mean_pool, global_max_pool, BatchNorm,  global_add_pool, EdgeConv, DynamicEdgeConv\n",
    "\n",
    "from graphnet.models.gnn.dynedge import DynEdge\n",
    "from graphnet.components.layers import DynEdgeConv\n",
    "from graphnet.models.gnn.gnn import GNN\n",
    "from graphnet.models.utils import calculate_xyzt_homophily, calculate_xyz_homophily_POne\n",
    "\n",
    "from multiprocessing import Pool\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA\n"
     ]
    }
   ],
   "source": [
    "outpath = \".\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA')\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_events(v_x):\n",
    "    path_to_events = \"/dss/pone/pone_events\"\n",
    "    det, cascades, cascade_records = pickle.load(open(os.path.join(path_to_events, f\"cascades1500_vx{v_x}.pickle\"), \"rb\"))\n",
    "    det, tracks, track_records = pickle.load(open(os.path.join(path_to_events, f\"tracks1500_vx{v_x}.pickle\"), \"rb\"))\n",
    "    det, stracks, strack_records = pickle.load(open(os.path.join(path_to_events, f\"starting_tracks1500_vx{v_x}.pickle\"), \"rb\"))\n",
    "    \n",
    "    return det, cascades, cascade_records, tracks, track_records, stracks, strack_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loaders_vx(v_x):\n",
    "    R=75\n",
    "    det, cascades, cascade_records, tracks, track_records, stracks, strack_records = load_test_events(v_x)\n",
    "    cascade_labels, track_labels, strack_labels = event_labelling(track_records, strack_records, cascade_records, det_hull=(R,1000))\n",
    "    all_events = cascades + tracks + stracks\n",
    "    all_records = cascade_records + track_records + strack_records\n",
    "    all_labels = cascade_labels + track_labels + strack_labels\n",
    "    data_array_test = generate_features(det, all_events, all_labels, k=15)\n",
    "    pickle.dump(data_array_test,open(f\"/dss/pone/pone_events/features_arrays/test_data_array/vx_data_arrays/data_array_{4.5}k_k{15}_R{R}_v_x{v_x}.pickle\", \"wb\"))\n",
    "    loader = DataLoader(data_array_test, batch_size=200, shuffle=False)\n",
    "    pickle.dump(data_array_test,open(f\"/dss/pone/pone_events/features_arrays/test_data_array/vx_loaders/test_loader_k{15}_R{R}_v_x{v_x}.pickle\", \"wb\"))\n",
    "    print(f\"speed {v_x} done\")\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6e194c72d54939b490e63fb8efb1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.005 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2f6c74ac904cf9b2ca178fac066402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.01 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d779b76dfe5446ea8c9e167d2ef66163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.015 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4345e6e1f47540ef94e2f78113c43505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.02 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f217c3be9ac74de5a8795dc3572ee491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.025 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f987aa05241642e3b09117aabdcd3f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.03 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6264c136974f51993f0bf3ae534797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.035 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042dc15e90cc41ca91fd6a4c7c8bdaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.04 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98adf81e5e81404ab444c58fc8d4e7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.045 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec67b2e35a74e2b9e752d139114f9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.05 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fad972fb0124ef2843952d8c194a84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.055 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3b28c999e144f99c1e182f211ccef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.06 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e0e749b1eb4add9cc039183098b2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.065 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9e4a6981484217a6674657674b427b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.07 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fcb7343c394691b0badac483d2a054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.075 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e900ebc5bf4175b9d76057d14724e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.08 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5855f74c8af40a5a7d79d68865a0a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.085 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d07b94ebc44478992c84a2df7fb876e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.09 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa16489fe394035847351f97441ce42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.095 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf58d3c08c242a1a1a65b25e4c367eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 0.1 done\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_3652338/2402793800.py\", line 8, in generate_loaders_vx\n    data_array_test = generate_features(det, all_events, all_labels, k=15)\n  File \"/home/work/software/arturo/repos/nemesis/nemesis/node_features/feature_generation.py\", line 76, in generate_features\n    data = torch_geometric.data.Data(x, edge_index, y=torch.tensor([label], dtype=torch.int64)).to(device)\n  File \"/home/work/.local/lib/python3.10/site-packages/torch_geometric/data/data.py\", line 251, in to\n    return self.apply(\n  File \"/home/work/.local/lib/python3.10/site-packages/torch_geometric/data/data.py\", line 234, in apply\n    store.apply(func, *args)\n  File \"/home/work/.local/lib/python3.10/site-packages/torch_geometric/data/storage.py\", line 159, in apply\n    self[key] = recursive_apply(value, func)\n  File \"/home/work/.local/lib/python3.10/site-packages/torch_geometric/data/storage.py\", line 510, in recursive_apply\n    return func(data)\n  File \"/home/work/.local/lib/python3.10/site-packages/torch_geometric/data/data.py\", line 252, in <lambda>\n    lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n  File \"/home/work/.local/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 207, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/work/software/arturo/repos/nemesis/generate_test_loaders.ipynb Cell 5\u001b[0m in \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.195.8.98/home/work/software/arturo/repos/nemesis/generate_test_loaders.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.195.8.98/home/work/software/arturo/repos/nemesis/generate_test_loaders.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mwith\u001b[39;00m Pool(\u001b[39m10\u001b[39m) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.195.8.98/home/work/software/arturo/repos/nemesis/generate_test_loaders.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         loader \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mmap(generate_loaders_vx, v_x_all)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method"
     ]
    }
   ],
   "source": [
    "v_x_all = [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08, 0.085, 0.09, 0.095, 0.1]\n",
    "for v_x in v_x_all:\n",
    "    generate_loaders_vx(v_x)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(10) as p:\n",
    "        loader = p.map(generate_loaders_vx, v_x_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loaders_vx(v_x):\n",
    "    R=100\n",
    "    det, cascades, cascade_records, tracks, track_records, stracks, strack_records = load_test_events(v_x)\n",
    "    cascade_labels, track_labels, strack_labels = event_labelling(track_records, strack_records, cascade_records, det_hull=(R,1000))\n",
    "    all_events = cascades + tracks + stracks\n",
    "    all_records = cascade_records + track_records + strack_records\n",
    "    all_labels = cascade_labels + track_labels + strack_labels\n",
    "    data_array_test = generate_features(det, all_events, all_labels, k=15)\n",
    "    pickle.dump(data_array_test,open(f\"/dss/pone/pone_events/features_arrays/test_data_array/vx_data_arrays/data_array_{4.5}k_k{15}_R{R}_v_x{v_x}.pickle\", \"wb\"))\n",
    "    loader = DataLoader(data_array_test, batch_size=200, shuffle=False)\n",
    "    pickle.dump(data_array_test,open(f\"/dss/pone/pone_events/features_arrays/test_data_array/vx_loaders/test_loader_k{15}_R{R}_v_x{v_x}.pickle\", \"wb\"))\n",
    "    print(f\"speed {v_x} done\")\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x_all = [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08, 0.085, 0.09, 0.095, 0.1]\n",
    "for v_x in v_x_all:\n",
    "    generate_loaders_vx(v_x)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(10) as p:\n",
    "        loader = p.map(generate_loaders_vx, v_x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
