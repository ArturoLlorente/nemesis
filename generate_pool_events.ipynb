{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ae16c-b76e-4bfe-94c1-764d7db9c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from nemesis.event_generation.generate_multiCPU import events_wrapped\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ddab1-8cc5-4256-98e0-136d09cd4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seed = 4500001\n",
    "event_types = ['cascades', 'tracks', 'starting_tracks']\n",
    "starting_it = 10\n",
    "\n",
    "\n",
    "for it in range(10):\n",
    "    indexes_all = []\n",
    "    seed_start = first_seed + 1600*it\n",
    "    event_type = event_types[0]\n",
    "    v_x = (1 + it)/100\n",
    "    print(v_x)\n",
    "    #v_x = 0\n",
    "    n_proc = 15\n",
    "    n_events_per_process = 100\n",
    "    seed_starts = range(seed_start, seed_start+n_proc*n_events_per_process, n_events_per_process)\n",
    "    for v in seed_starts:\n",
    "        indexes_all.append([event_type, v_x, v])\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        with Pool(n_proc) as p:\n",
    "            all_res = p.map(events_wrapped, indexes_all)\n",
    "    \n",
    "    events = []\n",
    "    records = []\n",
    "    for i in range(0, len(all_res)):\n",
    "        for j in range(100):\n",
    "            events.append(all_res[i][0][j])\n",
    "            records.append(all_res[i][1][j])\n",
    "    pickle.dump((events, records), open(f\"/dss/pone/pone_events/{event_type}{len(events)}_vx{v_x}.pickle\", \"wb\"))\n",
    "    print(f'iteration number {it} completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf8955-cf8c-4fe0-b6dc-f05e0654f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seed = 2600001\n",
    "event_types = ['cascades', 'tracks', 'starting_tracks']\n",
    "starting_it = 10\n",
    "\n",
    "for it in range(10):\n",
    "    indexes_all = []\n",
    "    seed_start = first_seed + 1600*it\n",
    "    event_type = event_types[1]\n",
    "    v_x = (0.5 + it)/100\n",
    "    #v_x = 0\n",
    "    n_proc = 15\n",
    "    n_events_per_process = 100\n",
    "    seed_starts = range(seed_start, seed_start+n_proc*n_events_per_process, n_events_per_process)\n",
    "    for v in seed_starts:\n",
    "        indexes_all.append([event_type, v_x, v])\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        with Pool(n_proc) as p:\n",
    "            all_res = p.map(events_wrapped, indexes_all)\n",
    "    \n",
    "    events = []\n",
    "    records = []\n",
    "    for i in range(0, len(all_res)):\n",
    "        for j in range(100):\n",
    "            events.append(all_res[i][0][j])\n",
    "            records.append(all_res[i][1][j])\n",
    "    pickle.dump((events, records), open(f\"/dss/pone/pone_events/{event_type}{len(events)}_vx{v_x}.pickle\", \"wb\"))\n",
    "    print(f'iteration number {it} completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc4e03-a96f-42e6-9aba-186d485d4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seed = 2700002\n",
    "event_types = ['cascades', 'tracks', 'starting_tracks']\n",
    "starting_it = 10\n",
    "\n",
    "for it in range(10):\n",
    "    indexes_all = []\n",
    "    seed_start = first_seed + 1600*it\n",
    "    event_type = event_types[2]\n",
    "    v_x = (0.5 + it)/100\n",
    "    #v_x = 0\n",
    "    n_proc = 15\n",
    "    n_events_per_process = 100\n",
    "    seed_starts = range(seed_start, seed_start+n_proc*n_events_per_process, n_events_per_process)\n",
    "    for v in seed_starts:\n",
    "        indexes_all.append([event_type, v_x, v])\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        with Pool(n_proc) as p:\n",
    "            all_res = p.map(events_wrapped, indexes_all)\n",
    "    \n",
    "    events = []\n",
    "    records = []\n",
    "    for i in range(0, len(all_res)):\n",
    "        for j in range(100):\n",
    "            events.append(all_res[i][0][j])\n",
    "            records.append(all_res[i][1][j])\n",
    "    pickle.dump((events, records), open(f\"/dss/pone/pone_events/{event_type}{len(events)}_vx{v_x}.pickle\", \"wb\"))\n",
    "    print(f'iteration number {it} completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b65454d-b02b-4ab1-b118-085b4ec9b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.10/site-packages/jax/_src/api_util.py:222: SyntaxWarning: Jitted function has invalid argnames {'interactions'} in static_argnames. Function does not take these args.This warning will be replaced by an error after 2022-08-20 at the earliest.\n",
      "  warnings.warn(f\"Jitted function has invalid argnames {invalid_argnames} \"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import functools\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"0.8\"\n",
    "import sys\n",
    "sys.path.insert(0, '../olympus')\n",
    "sys.path.insert(0, '../hyperion')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "from olympus.event_generation.photon_propagation.norm_flow_photons import make_generate_norm_flow_photons, make_nflow_photon_likelihood\n",
    "from olympus.event_generation.photon_propagation.utils import sources_to_model_input\n",
    "from nemesis.event_generation.detector import Detector, make_line, make_triang\n",
    "from olympus.event_generation.event_generation import (\n",
    "    generate_cascade,\n",
    "    generate_cascades,\n",
    "    simulate_noise,\n",
    "    generate_realistic_track,\n",
    "    generate_realistic_tracks,\n",
    "    generate_realistic_tracks_test,\n",
    "    generate_realistic_starting_tracks,)\n",
    "from olympus.event_generation.lightyield import make_pointlike_cascade_source, make_realistic_cascade_source\n",
    "from olympus.event_generation.utils import sph_to_cart_jnp, proposal_setup\n",
    "\n",
    "#from olympus.plotting import plot_event\n",
    "from hyperion.medium import medium_collections\n",
    "from hyperion.constants import Constants\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "import json\n",
    "\n",
    "path_to_config = \"../hyperion/data/pone_config_optimistic.json\"\n",
    "config = json.load(open(path_to_config))[\"photon_propagation\"]\n",
    "ref_ix_f, sca_a_f, sca_l_f, _ = medium_collections[config[\"medium\"]]\n",
    "\n",
    "def c_medium_f(wl):\n",
    "    \"\"\"Speed of light in medium for wl (nm).\"\"\"\n",
    "    return Constants.BaseConstants.c_vac / ref_ix_f(wl)\n",
    "\n",
    "rng = np.random.RandomState(31338)\n",
    "oms_per_line = 20\n",
    "dist_z = 50 # m\n",
    "dark_noise_rate = 16 * 1e-5  # 1/ns\n",
    "side_len = 100 # m\n",
    "pmts_per_module = 16\n",
    "pmt_cath_area_r = 75E-3 / 2 # m\n",
    "module_radius = 0.21 # m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7d1608-7e08-4760-a423-f2681c0b9cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m---> 33\u001b[0m         all_ev \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_test_events\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(all_ev)):\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_test_events(v_x):\n",
    "    path_to_events = \"/dss/pone/pone_events\"\n",
    "    det, cascades, cascade_records = pickle.load(open(os.path.join(path_to_events, f\"cascades1500_vx{v_x}.pickle\"), \"rb\"))\n",
    "    det, tracks, track_records = pickle.load(open(os.path.join(path_to_events, f\"tracks1500_vx{v_x}.pickle\"), \"rb\"))\n",
    "    det, stracks, strack_records = pickle.load(open(os.path.join(path_to_events, f\"starting_tracks1500_vx{v_x}.pickle\"), \"rb\"))\n",
    "    \n",
    "    all_ev = [det, cascades, cascade_records, tracks, track_records, stracks, strack_records]\n",
    "    \n",
    "    return all_ev\n",
    "    \n",
    "    \n",
    "cascades_test, cascade_records_test = [], []\n",
    "tracks_test, track_records_test = [], []\n",
    "stracks_test, strack_records_test = [], []\n",
    "det_test = []\n",
    "v_x_all = []\n",
    "\n",
    "for it in range(1,21):\n",
    "    v_x_all.append(np.round(it*0.005, 3))\n",
    "\n",
    "for i in range(2):\n",
    "    v_x = v_x_all[(y*10):((y+1)*10)]\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(10) as p:\n",
    "            all_ev = p.map(load_test_events, v_x)\n",
    "    print(f\"iteration {i} done\")\n",
    "\n",
    "\n",
    "    for v in range(len(all_ev)):\n",
    "        det_test.append(all_ev[v][0])\n",
    "        cascades_test += all_ev[v][1]\n",
    "        cascade_records_test += all_ev[v][2]\n",
    "        tracks_test += all_ev[v][3]\n",
    "        track_records_test += all_ev[v][4]    \n",
    "        stracks_test += all_ev[v][5]\n",
    "        strack_records_test += all_ev[v][6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
